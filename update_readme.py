import requests
from bs4 import BeautifulSoup
import time

# ğŸ”¹ ë°±ì¤€ ì•„ì´ë”” ì„¤ì •
BAEKJOON_ID = "myf6magic05"

# ğŸ”¹ Solved.ac APIë¡œ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
user_url = f"https://solved.ac/api/v3/user/show?handle={BAEKJOON_ID}"
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

try:
    user_response = requests.get(user_url, headers=headers)
    user_response.raise_for_status()
    user_data = user_response.json()
except requests.exceptions.RequestException as e:
    print(f"Failed to fetch user data from Solved.ac: {e}")
    exit(1)

# ğŸ”¹ Solved.ac í”„ë¡œí•„ í˜ì´ì§€ì—ì„œ í‘¼ ë¬¸ì œ ëª©ë¡ í¬ë¡¤ë§
solvedac_profile_url = f"https://solved.ac/profile/{BAEKJOON_ID}"
try:
    profile_response = requests.get(solvedac_profile_url, headers=headers)
    profile_response.raise_for_status()
except requests.exceptions.RequestException as e:
    print(f"Failed to fetch Solved.ac profile: {e}")
    exit(1)

soup = BeautifulSoup(profile_response.text, "html.parser")

# ğŸ”¹ Solved.ac í”„ë¡œí•„ í˜ì´ì§€ì—ì„œ í‘¼ ë¬¸ì œ ëª©ë¡ ì°¾ê¸°
# 2025ë…„ 3ì›” ê¸°ì¤€ìœ¼ë¡œ Solved.ac í”„ë¡œí•„ í˜ì´ì§€ì—ì„œ í‘¼ ë¬¸ì œ ëª©ë¡ì€
# <div class="css-1k3iieq"> íƒœê·¸ ì•ˆì— ìˆëŠ” <a> íƒœê·¸ë“¤ë¡œ í‘œì‹œë¨
problem_list_div = soup.find("div", {"class": "css-1k3iieq"})
if not problem_list_div:
    print("Could not find problem list div in Solved.ac profile. Check if the HTML structure has changed.")
    exit(1)

problems = problem_list_div.find_all("a") if problem_list_div else []
problem_ids = []

for problem in problems:
    href = problem.get("href")
    if href and "/problem/" in href:
        problem_id = href.split("/")[-1]  # hrefì—ì„œ ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: /problem/1000 -> 1000)
        problem_ids.append(problem_id)

# ğŸ”¹ Solved.ac APIë¡œ ë¬¸ì œ ì œëª© ê°€ì ¸ì˜¤ê¸°
problem_list = []
for problem_id in problem_ids:
    lookup_url = f"https://solved.ac/api/v3/problem/lookup?problemIds={problem_id}"
    try:
        lookup_response = requests.get(lookup_url, headers=headers)
        lookup_response.raise_for_status()
        problem_data = lookup_response.json()
        time.sleep(1)  # ìš”ì²­ ê°„ê²© ì¶”ê°€
    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch problem data from Solved.ac: {e}")
        continue

    if problem_data and len(problem_data) > 0:
        problem_info = problem_data[0]
        problem_title = problem_info["titleKo"]  # í•œêµ­ì–´ ì œëª©
        problem_url = f"https://www.acmicpc.net/problem/{problem_id}"
        problem_list.append((problem_id, problem_title, problem_url))

# ğŸ”¹ README íŒŒì¼ ì—…ë°ì´íŠ¸
with open("README.md", "w", encoding="utf-8") as f:
    f.write(f"# ë°±ì¤€ ë¬¸ì œ í’€ì´ ê¸°ë¡\n\n")
    f.write(f"## {BAEKJOON_ID}ë‹˜ì˜ ë°±ì¤€ ë¬¸ì œ í’€ì´ í˜„í™©\n\n")
    f.write(f"### í•´ê²°í•œ ë¬¸ì œ ({len(problem_list)}ê°œ)\n\n")
    for num, title, url in problem_list:
        f.write(f"- [{num}. {title}]({url})\n")
