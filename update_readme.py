import requests
from bs4 import BeautifulSoup
import time

# ğŸ”¹ ë°±ì¤€ ì•„ì´ë”” ì„¤ì •
BAEKJOON_ID = "myf6magic05"

# ğŸ”¹ ë°±ì¤€ í”„ë¡œí•„ í˜ì´ì§€ í¬ë¡¤ë§
url = f"https://www.acmicpc.net/user/{BAEKJOON_ID}"
try:
    response = requests.get(url)
    response.raise_for_status()
except requests.exceptions.RequestException as e:
    print(f"Failed to fetch Baekjoon profile: {e}")
    exit(1)

soup = BeautifulSoup(response.text, "html.parser")
solved_problems = soup.find("span", {"id": "solved-problem"})
if not solved_problems:
    print("Could not find solved-problem span. Check if the HTML structure has changed.")
    exit(1)

problems = solved_problems.find_all("a") if solved_problems else []
problem_list = []

for problem in problems:
    problem_number = problem.text.strip()
    problem_url = f"https://www.acmicpc.net/problem/{problem_number}"
    
    # ğŸ”¹ ê°œë³„ ë¬¸ì œ í˜ì´ì§€ì—ì„œ ë¬¸ì œ ì œëª© ê°€ì ¸ì˜¤ê¸°
    try:
        problem_page = requests.get(problem_url)
        problem_page.raise_for_status()
        time.sleep(1)  # ìš”ì²­ ê°„ê²© ì¶”ê°€
    except requests.exceptions.RequestException as e:
        print(f"Failed to fetch problem page {problem_url}: {e}")
        continue

    problem_soup = BeautifulSoup(problem_page.text, "html.parser")
    problem_title = problem_soup.find("span", {"id": "problem_title"})
    if problem_title:
        problem_title = problem_title.text.strip()
    else:
        problem_title = "Unknown Title"

    problem_list.append((problem_number, problem_title, problem_url))

# ğŸ”¹ README íŒŒì¼ ì—…ë°ì´íŠ¸
with open("README.md", "w", encoding="utf-8") as f:
    f.write(f"# ë°±ì¤€ ë¬¸ì œ í’€ì´ ê¸°ë¡\n\n")
    f.write(f"## {BAEKJOON_ID}ë‹˜ì˜ ë°±ì¤€ ë¬¸ì œ í’€ì´ í˜„í™©\n\n")
    f.write(f"### í•´ê²°í•œ ë¬¸ì œ ({len(problem_list)}ê°œ)\n\n")
    for num, title, url in problem_list:
        f.write(f"- [{num}. {title}]({url})\n")
